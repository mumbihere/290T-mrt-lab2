{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['negative', 'positive', 'fromstring']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from typing import Tuple\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import json\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "\n",
    "dataset = pd.read_csv('data/multisession-eeg.csv')\n",
    "fromstring = lambda array_str: np.fromstring(array_str, dtype=float, sep=',')\n",
    "dataset.raw_fft = dataset.raw_fft.apply(fromstring)\n",
    "# dataset.raw_fft.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>subject</th>\n",
       "      <th>session</th>\n",
       "      <th>label</th>\n",
       "      <th>raw_fft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-07-22T20:37:13.267775811Z</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>[10.3113040924, 14.77069664, 12.213514328, 9.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-07-22T20:37:14.253040444Z</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>[11.2151269913, 14.9568557739, 10.8369417191, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-07-22T20:37:15.372317746Z</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>[6.34600162506, 12.5924711227, 10.8416910172, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-07-22T20:37:16.483798739Z</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>[10.0782966614, 16.9934558868, 18.5345039368, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-07-22T20:37:17.471855277Z</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>[4.42960739136, 9.05199050903, 4.41912555695, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             time subject  session      label  \\\n",
       "0  2017-07-22T20:37:13.267775811Z       A        0  unlabeled   \n",
       "1  2017-07-22T20:37:14.253040444Z       A        0  unlabeled   \n",
       "2  2017-07-22T20:37:15.372317746Z       A        0  unlabeled   \n",
       "3  2017-07-22T20:37:16.483798739Z       A        0  unlabeled   \n",
       "4  2017-07-22T20:37:17.471855277Z       A        0  unlabeled   \n",
       "\n",
       "                                             raw_fft  \n",
       "0  [10.3113040924, 14.77069664, 12.213514328, 9.7...  \n",
       "1  [11.2151269913, 14.9568557739, 10.8369417191, ...  \n",
       "2  [6.34600162506, 12.5924711227, 10.8416910172, ...  \n",
       "3  [10.0782966614, 16.9934558868, 18.5345039368, ...  \n",
       "4  [4.42960739136, 9.05199050903, 4.41912555695, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['A', 'B', 'C'], dtype=object),\n",
       " array(['unlabeled', 'breathe', 'song', 'song_o', 'sport', 'breathe_o',\n",
       "        'speech', 'face', 'calibration', 'word_x', 'phrase_x', 'face_x',\n",
       "        'breatheopen', 'song_x', 'sport_x', 'breatheclosed', 'word_c',\n",
       "        'phrase_c', 'face_c', 'song_c', 'sport_c'], dtype=object))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['subject'].unique(),dataset['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passthoughts\n",
    "\n",
    "What if you could simply *think your password*? That's the premise behind *passthoughts*. We'll discuss passthoughts in more depth in lecture 3, but for now, we'll lay this out as a classification problem:\n",
    "\n",
    "> Given a reading, and a person, is that person who they claim to be?\n",
    "\n",
    "We'll structure this problem as follows: For each subject, we'll train a classifier. That subject's readings will be positive example, and everyone else's readings will be negative examples.\n",
    "\n",
    "We can make this a little fancier by having people use specific thoughts (e.g. \"focus on your breathing,\" \"sing a song in your head,\" etc). We'll make sure our methods can handle this case, but for the time being, we'll just use the `\"unabeled\"` readings - people doing nothing in particular.\n",
    "\n",
    "We'll use subject `A` as our \"target\" individual. We will train on this subject for this assignment, and train against the other subjects in the corpus (subjects `B` and `C`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_matrix (series):\n",
    "    return np.array([ x for x in series ])\n",
    "\n",
    "def readings_right_subject_right_task (subj, task, session=0):\n",
    "    return to_matrix(dataset[\n",
    "        (dataset['subject'] == subj) &\n",
    "        (dataset['label'] == task) &\n",
    "        (dataset['session'] == session)\n",
    "    ].raw_fft)\n",
    "\n",
    "def readings_wrong_subj_any_task (subj):\n",
    "    return to_matrix(dataset[\n",
    "        (dataset['subject'] != subj)\n",
    "    ].raw_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 516), (40, 516))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = readings_right_subject_right_task('A', 'unlabeled', 0)\n",
    "negative = readings_wrong_subj_any_task('A')\n",
    "positive.shape, positive.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "Notice how we structured our positive and negative examples:\n",
    "\n",
    "- *Positive examples*: The right person thinking the right task.\n",
    "\n",
    "- *Negative examples*: The wrong person thinking any task (whether it is right or wrong).\n",
    "\n",
    "In the context of passthoughts, consider other possibilites for selecting positive and negative features. Here, (1) pick one configuration of positive and negative examples, aside from the ones listed, and (2) discuss their possible consequences (pros/cons). Explain how you might evaluate this selection (with data, with user experiments, etc - your choice)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Your answer here...*\n",
    "\n",
    "Another possible configuration of positive and negative examples is:\n",
    "- *Positive example*:*: The right person thinking any task\n",
    "- *Negative examples*: The wrong person thinking any task (whether it is right or wrong) \n",
    "\n",
    "This configuration puts the emphasis on the subject rather than the password. It assumes that it is more important to authenticate the right person(regardless of what passthought they have) than to always have a correct password/passthought presented.\n",
    "\n",
    "Another possible configuration is\n",
    "\n",
    "- *Positive example*:*: The right person thinking the right task. \n",
    "- *Negative examples*: The wrong person thinking any task (whether it is right or wrong) and the right person thinking the wrong thing\n",
    "\n",
    "This configurations puts an emphasis on whether the right passthought is presented and less on who is presenting the passthought. This is closer to existing authentication techniques that use passwords and that deny access to the right user if they forget the password.\n",
    " \n",
    "##### Explain how you might evaluate this selection (with data, with user experiments, etc - your choice)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll turn these data into our feature/label matrices `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.concatenate([positive, negative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array([ 0 for x in positive] + [ 1 for x in negative])\n",
    "assert X.shape[0] == y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are assigning `0` to \"positive\" examples, and `1` to \"negative\" examples. That means `0` will mean \"ACCEPT\" and `1` will mean \"REJECT.\"\n",
    "\n",
    "## TODO\n",
    "\n",
    "Now, train and test a classifier! Estimate your classifier's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here....\n",
    "\n",
    "#Define X\n",
    "\n",
    "\n",
    "#Define y\n",
    "\n",
    "\n",
    "def fresh_clf () -> XGBClassifier:\n",
    "    return XGBClassifier(\n",
    "        # Don't worry about those parameters for now,\n",
    "        # though feel free to look them up if you're interested.\n",
    "        objective= 'binary:logistic',\n",
    "        seed=27)\n",
    "\n",
    "def xgb_cross_validate (\n",
    "    X: np.array,\n",
    "    y: np.array,\n",
    "    nfold: int=7\n",
    ") -> Tuple[XGBClassifier, pd.DataFrame]:\n",
    "    # eval_metrics:\n",
    "    # http://xgboost.readthedocs.io/en/latest//parameter.html\n",
    "    metrics = ['error@0.1', 'auc']\n",
    "#     metrics = [ 'auc' ]\n",
    "    # we use the @ syntax to override the default of 0.5 as the threshold for 0 / 1 classification\n",
    "    # the intent here to to minimize FAR at the expense of FRR\n",
    "    alg = fresh_clf()\n",
    "    xgtrain = xgb.DMatrix(X,y)\n",
    "    param = alg.get_xgb_params()\n",
    "    cvresults = xgb.cv(param,\n",
    "                      xgtrain,\n",
    "                      num_boost_round=alg.get_params()['n_estimators'],\n",
    "                      nfold=nfold,\n",
    "                      metrics=metrics,\n",
    "                      early_stopping_rounds=100\n",
    "                      )\n",
    "    alg.set_params(n_estimators=cvresults.shape[0])\n",
    "    alg.fit(X,y,eval_metric=metrics)\n",
    "    return alg, cvresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-92bb7dbcb1bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train, X_validate, y_train, y_validate = model_selection.train_test_split(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     random_state=42)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_validate, y_train, y_validate = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.33, \n",
    "    random_state=42)\n",
    "\n",
    "clf, cvres = xgb_cross_validate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98329355608591884"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For authentication, what we want even more than \"accuracy\" here are two metrics:\n",
    "\n",
    "- False Acceptance Rate (FAR): The percentage of readings *not* from subject A incorrectly classified \"ACCEPT.\"\n",
    "- False Rejection Rate (FRR): The percentage of readings *from* subject A incorrectly classified 'REJECT.\"\n",
    "\n",
    "For authentication /security/, we want FAR to be as low as possible (so nobody can break in).\n",
    "For authentication /usability/, we want FRR to be low (so user's don't get frustrated constantly re-trying their passthought)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def far_frr (classifier, features, labels):\n",
    "    # predict all the labels\n",
    "    y_pred = classifier.predict(features)\n",
    "    false_accepts = 0\n",
    "    false_rejects = 0\n",
    "    for predicted, actual in zip(y_pred, labels):\n",
    "        # if we should have rejected,\n",
    "        # but in fact accepted,\n",
    "        if (actual == 1) and (predicted == 0):\n",
    "            # increment false accepts\n",
    "            false_accepts += 1\n",
    "        # if we should have accepted,\n",
    "        # but in fact rejected,\n",
    "        if (actual == 0) and (predicted == 1):\n",
    "            # increment false rejections\n",
    "            false_rejects += 1\n",
    "    # calculate proportions for each\n",
    "    far = false_accepts / len(y_pred)\n",
    "    frr = false_rejects / len(y_pred)\n",
    "    return far, frr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FAR: 0.007159904534606206 - FRR: 0.00954653937947494'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "far, frr = far_frr(clf, X_validate, y_validate)\n",
    "f'FAR: {far} - FRR: {frr}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, these results might be good. \n",
    "\n",
    "But our classifier's accuracy could be misleading.   \n",
    "\n",
    "Can you see why? \n",
    "\n",
    "# Nonstationarity\n",
    "\n",
    "We are training, and testing, using data recorded over a single session. As we know, EEG changes over time, a property known as *nonstationarity*. Will our great results still hold a few weeks later?\n",
    "\n",
    "Let's take subject `A`'s data from sessions 1 and 2, which were recorded a few weeks after session 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_subja_sess1 = readings_right_subject_right_task('A', 'unlabeled', 1)\n",
    "X_subja_sess2 = readings_right_subject_right_task('A', 'unlabeled', 2)\n",
    "X_subja_later = np.concatenate([X_subja_sess1, X_subja_sess2])\n",
    "y_subja_later = [ 0 for x in X_subja_later ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try the classifier we trained on the original data, testing it on the later data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FAR: 0.0% - FRR: 84.90259740259741%'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "far, frr = far_frr(clf, X_subja_later, y_subja_later)\n",
    "f'FAR: {far*100}% - FRR: {frr*100}%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will discuss more in lecture 3, this is a problem for us. After all, we can calibrate our target subject, but we then expect them to leave the lab and go use the device later on. If their state changes so much that they can no longer be authenticated, we can't very well claim our system is accurate!\n",
    "\n",
    "## TODO\n",
    "\n",
    "The crux of the lab focuses on nonstationarity. At minimum, your mission is to quantify and qualify *what* is changing in EEG signals over time. You may use any tools in answering this question.\n",
    "\n",
    "You also have your choice of corpus:\n",
    "\n",
    "- Study subject `A`'s recordings over the three sessions provided here.\n",
    "- Study one subject's recordings over the course of a year.\n",
    "\n",
    "You can use both of these corpora, if you would like.\n",
    "\n",
    "Some questions to spur investigation:\n",
    "\n",
    "- What features of readings cause a classifier that works on earlier recordings fail on later ones?\n",
    "- What features remain the same? Are there any?\n",
    "- What might be the source of these changing features? Changing placement in the EEG device? Changing properties of the brain?\n",
    "\n",
    "Please note below all work you do, and any notes you make along the way. Ideally, your work should read like a story - words (and questions!) interspersed with code. Good luck, and have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
